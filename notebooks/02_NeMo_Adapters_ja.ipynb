{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yS2xVGrLrphl"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "You can run either this notebook locally (if you have all the dependencies and a GPU) or on Google Colab.\n",
        "\n",
        "Instructions for setting up Colab are as follows:\n",
        "1. Open a new Python 3 notebook.\n",
        "2. Import this notebook from GitHub (File -> Upload Notebook -> \"GITHUB\" tab -> copy/paste GitHub URL)\n",
        "3. Connect to an instance with a GPU (Runtime -> Change runtime type -> select \"GPU\" for hardware accelerator)\n",
        "4. Run this cell to set up dependencies.\n",
        "\"\"\"\n",
        "# If you're using Google Colab and not running locally, run this cell.\n",
        "\n",
        "## Install dependencies\n",
        "!apt-get install sox libsndfile1 ffmpeg\n",
        "!pip install wget\n",
        "!pip install text-unidecode\n",
        "\n",
        "# ## Install NeMo\n",
        "BRANCH = 'main'\n",
        "!python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH#egg=nemo_toolkit[all]\n",
        "\n",
        "## Grab the config we'll use in this example\n",
        "!mkdir configs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivKMObsjy9Om"
      },
      "source": [
        "# NeMoモデルにおけるアダプタサポート",
        "\n",
        "NeMoでは、モデルを訓練した後、特定のタスク向けにファインチューニングすることが一般的です。これはモデルのパラメータ数が数百万程度の場合には合理的なアプローチです。しかし、数億から数十億パラメータ規模のモデルを扱う場合、このアプローチは急速に非現実的になります。",
        "\n",
        "このようなシナリオに対する潜在的な解決策として、大規模なモデルのファインチューニングが非現実的になった場合、私たちは特定のドメインやタスクに特化させるために[Adapter](https://arxiv.org/abs/1902.00751)を活用します。Adapterは元のモデルのパラメータ総数のほんの一部しか必要とせず、ファインチューニングにおいてはるかに効率的です。",
        "\n",
        "このチュートリアルでは、torch.nn.Moduleを更新してAdapterをサポートする方法と、さらにその応用として、NeMoモデルのコンポーネントに対してAdapterサポートを有効にする方法について解説します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ7mPouNEXjB"
      },
      "source": [
        "## アダプターとは何か？",
        "\n",
        "アダプターはシンプルな概念です。下図のように1つのアダプターを図示できます。最も単純な形態では、入力次元（$D$）を小さなボトルネック次元（$H$）に圧縮する残差フィードフォワード層であり、$R^D \\text{->} R^H$の計算を行い、活性化関数（例えばReLU）を適用した後、別のフィードフォワード層で$R^H \\text{->} R^D$のマッピングを行います。この出力は、単純な残差接続を介して入力に加算されます。",
        "\n",
        "<div align=\"center\">",
        "<img src=\"https://mermaid.ink/img/pako:eNptkLFqwzAQhl9F3ORAPDSjA4EUx6RgXEjbycpwWOdG1JaMfEoakrx7ZcfpUKrlxH_fz4d0gcoqggTqxp6qAzoW76k0Ipx1-WI6z3sRxyuRF1GOZ3KisK6d3YG8GFdZ9hRJeLbMDRmqvkRGpDLrTuiUiEWUigBtlyIVqzBnEqZ66I39dcX6iKytKXeUf-wn-286QoFeBMvmu0PTD-EfyXaQpP9JFmP_1XN4S3kfD8W4ue6o18pjc52gYQlzaMm1qFX4msuQSOADtSQhCdfaOupZgjS3QPpOIdNGabYOkhqbnuaAnu3b2VSQsPP0gFKNnw7bibr9AJkZdXU\" height=100% />",
        "</div>",
        "\n",
        "-----",
        "\n",
        "このようなアダプタモジュールは通常、初期化時にアダプタの初期出力が常にゼロとなるように設定されます。これにより、このようなモジュールを追加したことによって元のモデルの性能が低下するのを防ぎます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kE1oh1_IdLW"
      },
      "source": [
        "## 標準アーキテクチャのエミュレーション",
        "\n",
        "このチュートリアルでは、既存のアーキテクチャにアダプターサポートを追加する方法をデモンストレーションします。",
        "\n",
        "ここでは、単純な多層パーセプトロンを用いて実装した基本的なモデルに焦点を当てます。ただし、このモデル自体は標準的なエンコーダ・デコーダ構造をエミュレートします（音声認識、自然言語処理、機械翻訳など、複数の分野で一般的に使用されているアーキテクチャです）。",
        "\n",
        "また、データセット、データローダー、損失関数、評価指標、およびPyTorch Lightningの「ステップ」（トレーナー、検証、テスト）の実装は省略します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iYvsUFpIISX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from nemo.core import NeuralModule, ModelPT\n",
        "\n",
        "from hydra.utils import instantiate\n",
        "from omegaconf import DictConfig, OmegaConf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qchb0kHZ6xV"
      },
      "outputs": [],
      "source": [
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, dim: int = 50):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc = torch.nn.Linear(dim, dim)\n",
        "        self.ln = torch.nn.LayerNorm(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = self.ln(x)\n",
        "        return x\n",
        "\n",
        "class ResidualMLP(torch.nn.Module):\n",
        "  def __init__(self, dim: int, num_layers: int):\n",
        "    super().__init__()\n",
        "\n",
        "    self.dim = dim\n",
        "    self.num_layers = num_layers\n",
        "    self.layers = nn.ModuleList([MLP(dim) for _ in range(num_layers)])\n",
        "  \n",
        "  def forward(self, x):\n",
        "    input = x\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "      x = x + input\n",
        "      input = x\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgBYZMyFcJiO"
      },
      "source": [
        "-----",
        "次に、2つの「モジュール」を持つシンプルなモデルを実装します："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4lo4E-Abfm_"
      },
      "outputs": [],
      "source": [
        "class SimpleModel(ModelPT):\n",
        "    def __init__(self, cfg, trainer=None):\n",
        "        super().__init__(cfg, trainer=trainer)\n",
        "\n",
        "        self.encoder = instantiate(cfg.encoder)  # type: ResidualMLP\n",
        "        self.decoder = instantiate(cfg.decoder)  # type: ResidualMLP\n",
        "        self.projection = nn.Linear(self.decoder.dim, cfg.out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.encoder(x)\n",
        "        z = self.decoder(y)\n",
        "        out = self.projection(z)\n",
        "        return out\n",
        "\n",
        "    def list_available_models(cls):\n",
        "        return []\n",
        "\n",
        "    def setup_training_data(self, train_data_config):\n",
        "        pass\n",
        "\n",
        "    def setup_validation_data(self, val_data_config):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE6401-Bdj-K"
      },
      "source": [
        "## 基本モデルの初期化",
        "\n",
        "上記のモデルは、エンコーダとデコーダブロックの2つのコンポーネントから構成されるシンプルな残差MLPネットワークです。実際のタスクでは十分な性能を発揮できないかもしれませんが、このデモンストレーションには十分です。",
        "\n",
        "次に、このモデル用の設定を生成するヘルパーを作成し、生成した設定を使用して新しいモデルを作成してみましょう！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xgMDKDvdbKw"
      },
      "outputs": [],
      "source": [
        "def get_classpath(cls):\n",
        "    return f'{cls.__module__}.{cls.__name__}'\n",
        "\n",
        "def get_model_config(dim=512):\n",
        "    config = OmegaConf.create(\n",
        "        {\n",
        "            'in_features': dim,\n",
        "            'out_features': 10,\n",
        "            'encoder': {'_target_': get_classpath(ResidualMLP), 'dim': dim, 'num_layers': 4},\n",
        "            'decoder': {'_target_': get_classpath(ResidualMLP), 'dim': dim, 'num_layers': 2},\n",
        "        }\n",
        "    )\n",
        "    return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuCHbKM6eXgs"
      },
      "outputs": [],
      "source": [
        "dim = 512\n",
        "model_cfg = get_model_config(dim)\n",
        "model = SimpleModel(model_cfg)\n",
        "model.summarize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ecba1X-6egs8"
      },
      "outputs": [],
      "source": [
        "# Check if the forward pass works !\n",
        "with torch.no_grad():\n",
        "  input_data = torch.randn(8, dim)\n",
        "  out = model(input_data)\n",
        "  print(out.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQUitVFafW6q"
      },
      "source": [
        "# アダプターの組み込み - モジュールごとに",
        "\n",
        "基本的なモデルが完成し、順方向パスが正常に実行できるようになった今、モデルとそのモジュールにアダプターサポートを追加できます。レイヤーごとに段階的に実装していきましょう。",
        "\n",
        "アダプターサポートの追加を検討する際、私たちは逆方向から作業します。最も低いレベルで使用されるモジュールから開始し、アダプターのメソッドを最上位の Model から最下位レベルのモジュール/レイヤーへと順に転送するチェーンを構築します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YcePlyLgUD4"
      },
      "source": [
        "# 最下位レベルモジュールにおけるアダプタサポート",
        "\n",
        "モデルチェーンを逆方向に辿ると、`Linear`層と`LayerNorm`層を生成する`MLP`モジュールに到達します。ここでは、`nemo.core.adapter_mixins`内で利用可能な`AdapterModuleMixin`をこのMLPモジュールに追加します。",
        "\n",
        "一般的にはモジュールのコードを直接更新することが推奨されますが、他にも実装方法があります（チュートリアルの後半で詳しく説明します）。",
        "\n",
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daSapfg0lpUj"
      },
      "source": [
        "## `mixin`とは何ですか？",
        "`mixin`とは一般的に、**他のクラスに継承される**クラス、あるいは**他のクラスに追加機能を提供する**クラスを指す用語です_。ただし単独では使用できません_。mixinは、複数の継承を通じてクラスに追加機能を組み込むための比較的安全な方法と緩やかに解釈できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXE2cJrre9SN"
      },
      "outputs": [],
      "source": [
        "from nemo.core import adapter_mixins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7m8MScqkw8_"
      },
      "outputs": [],
      "source": [
        "help(adapter_mixins.AdapterModuleMixin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ML_Uaig8iLKR"
      },
      "outputs": [],
      "source": [
        "# NOTE: See the *two* classes being inherited here !\n",
        "class MLP(torch.nn.Module, adapter_mixins.AdapterModuleMixin):\n",
        "    def __init__(self, dim: int = 50):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc = torch.nn.Linear(dim, dim)\n",
        "        self.ln = torch.nn.LayerNorm(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = self.ln(x)\n",
        "\n",
        "        # The only necessary change to the module code !\n",
        "        if self.is_adapter_available():\n",
        "          x = self.forward_enabled_adapters(x)\n",
        "        return x\n",
        "\n",
        "    # add a utility method to calculate number of parameters (or we could simple extend nemo.core.NeuralModule instead)\n",
        "    @property\n",
        "    def num_weights(self):\n",
        "      num: int = 0\n",
        "      for p in self.parameters():\n",
        "          if p.requires_grad:\n",
        "              num += p.numel()\n",
        "      return num"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUsZL7MJlKly"
      },
      "source": [
        "-----",
        "\n",
        "これで完了です！ほぼすべてのアダプターに対応したMLPレイヤーが完成しました！以下ではいくつかのアダプター機能を実際に試して、このチュートリアルをさらに進めていく際に期待できる機能の一端をお見せします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV4Ww-kHlc2_"
      },
      "source": [
        "## モジュールレベルアダプターの実験",
        "\n",
        "ここでは、先ほど拡張した `MLP` モデルをインスタンス化し、`AdapterModuleMixin` クラスを通じて追加されたすべての機能を探求します。追加の補助コードをほとんど記述することなく！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJBBbWFTmgni"
      },
      "source": [
        "-----",
        "\n",
        "まず、`MLP`モジュールを作成し、アダプタを追加する前の訓練可能なパラメータ数を表示しましょう"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUczqEM4lJYb"
      },
      "outputs": [],
      "source": [
        "mlp = MLP(dim)\n",
        "\n",
        "print(mlp)\n",
        "print(\"Num trainable parameters (without adapters):\", mlp.num_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY6rJroGmwEg"
      },
      "source": [
        "## Adapter Modules",
        "\n",
        "次に、このモジュールにアダプタを1つまたは2つインポートして追加してみましょう！まずNeMoの`common`コレクションから`adapter_modules`をインポートします。このモジュールには、他のtorch.nn.Moduleにアタッチ可能な事前定義済みのAdapterモジュールが含まれています！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dol4-4vmmenZ"
      },
      "outputs": [],
      "source": [
        "from nemo.collections.common.parts import adapter_modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtZtXNSHo1LB"
      },
      "outputs": [],
      "source": [
        "# Next we look at one of the adapter modules - the LinearAdapter\n",
        "linear_adapter = adapter_modules.LinearAdapter(in_features=dim, dim=5)\n",
        "print(linear_adapter)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----",
        "通常はこのモジュールを直接使用するのではなく、Config Dataclassを`AdapterModuleMixin`のメソッドに渡すことになります。以下に使用例を示します -"
      ],
      "metadata": {
        "id": "0E2877IlIVoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [任意] アダプターコンポーネントの構築",
        "\n",
        "線形アダプターモジュールは、作成可能なアダプターの唯一のタイプではありません！PyTorchでは、任意のtorch.nn.Moduleをアダプターコンポーネントに変換できます。",
        "\n",
        "例えば、既存のPyTorchモジュールをアダプターコンポーネントに変換することが可能です。以下のセクションは**任意**ですが、独自のアダプターを作成したい場合には推奨されます。"
      ],
      "metadata": {
        "id": "8eH6mW792lkY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------",
        "まず、簡単なPyTorchモジュールから始めましょう。"
      ],
      "metadata": {
        "id": "lgsyaQHI3w5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleModule(torch.nn.Module):\n",
        "  def __init__(self, size: int):\n",
        "    super().__init__()\n",
        "    self.size = size\n",
        "    self.model = torch.nn.Sequential(\n",
        "        torch.nn.Linear(size, size, bias=False),\n",
        "        torch.nn.Identity(),\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.model(x)"
      ],
      "metadata": {
        "id": "wAfA3r0b3fpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adapter Strategy",
        "\n",
        "アダプターモジュールは、本質的にはPyTorchのモジュールそのものです。PyTorchのモジュールと同様に、入力テンソルを受け取り、何らかの演算を実行した後、結果を返します。",
        "\n",
        "アダプターを統合する方法は複数あります：残差として追加する、要素ごとに乗算する、入力と連結する（末尾または先頭に追加）など。AdapterStrategyクラスは、アダプターが入力とどのように統合されるかを決定します。"
      ],
      "metadata": {
        "id": "hMKoxc0e5c14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The earlier LinearAdapter has a simple ResidualAddStrategy\n",
        "# Uncomment below to see the ResidualAddAdapterStrategy definition\n",
        "# help(linear_adapter.adapter_strategy)"
      ],
      "metadata": {
        "id": "1DVeRqH65IN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### カスタム Adapter Strategy の作成",
        "\n",
        "残差加算戦略は、単純な操作 $f(x) = x + アダプター(x)$ と考えることができ、ここで $アダプター$ の初期出力は訓練なしで 0 であるべきです。",
        "\n",
        "この処理において、アダプター拡張モデルの出力は本来 $f(x) = x$ であり、したがってモデルは元のモデル（アダプターなし）の性能をそのまま保持する。",
        "\n",
        "-----",
        "\n",
        "以下では、デモンストレーションとして単純な乗算アダプター戦略を作成します。"
      ],
      "metadata": {
        "id": "5mWowiS269h8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nemo.core.classes.mixins import adapter_mixin_strategies"
      ],
      "metadata": {
        "id": "teiTVBMq687x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下のようにアダプターの特殊メソッド `forward` を実装します："
      ],
      "metadata": {
        "id": "BS2W1a919KDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment to see the definition of the AbstractAdapterStrategy\n",
        "# help(adapter_mixin_strategies.AbstractAdapterStrategy)"
      ],
      "metadata": {
        "id": "G9_bq05P9Izh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiplicationAdapterStrategy(adapter_mixin_strategies.AbstractAdapterStrategy):\n",
        "\n",
        "  def __init__(self, scaling_factor: float = 1.0):\n",
        "    super().__init__()\n",
        "    self.scale = scaling_factor\n",
        "\n",
        "  def forward(self, input: torch.Tensor, adapter: torch.nn.Module, *, module: 'AdapterModuleMixin'):\n",
        "     # This is the forward method that takes in the previous input (here, its a tensor, but it can be a dictionary, a tuple, a class, anything really).\n",
        "     # The second argument is the adapter that is currently being applied to this input\n",
        "     # The final argument is the entire nn.Module that supports adapters.\n",
        "     # In this case, the final argument would be the entire `MLP` module\n",
        "     \n",
        "     # Equivalent to f(x) = x * adapter(x)\n",
        "     adapter_out = adapter(input)  # compute the adapter output from the input(s)\n",
        "     result = input * adapter_out\n",
        "\n",
        "     # Apply scaling factor. Equivalent to f(x) = scale * (x * adapter(x))\n",
        "     result = self.scale * result\n",
        "     return result\n"
      ],
      "metadata": {
        "id": "T3agPtjA3fst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adapter Strategyに対応するdataclassを設計する",
        "\n",
        "このクラスの使用を容易にするため、簡単に戦略オブジェクトを作成できる Dataclass を作成することをお勧めします。以下に使用例を示します："
      ],
      "metadata": {
        "id": "ZOS9Z3KVAGH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class MultiplicationAdapterStrategyConfig:\n",
        "    scaling_factor: float = 1.0\n",
        "\n",
        "    # mandatory field\n",
        "    _target_: str = \"{0}.{1}\".format(\n",
        "        MultiplicationAdapterStrategy.__module__, MultiplicationAdapterStrategy.__name__\n",
        "    )  "
      ],
      "metadata": {
        "id": "MI4oYRYDAeqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### カスタムアダプターコンポーネントの作成",
        "\n",
        "基本的なPyTorchモジュール (`SimpleModule`) とアダプタ戦略 (`MultiplicationAdapterStrategy`) の両方が用意できたので、新しいアダプタコンポーネントを構築できます。",
        "\n",
        "基本的なPyTorchモジュールとアダプターコンポーネントの本質的な違いは`adapter_strategy`にあります。これは、アダプターが元の入力とどのように統合されるかを定義するものです。"
      ],
      "metadata": {
        "id": "mZ22m_ZK_ifY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleModuleAdapter(SimpleModule, adapter_modules.AdapterModuleUtil):\n",
        "\n",
        "  def __init__(self, size: int, adapter_strategy: MultiplicationAdapterStrategy = None):\n",
        "    \"\"\"\n",
        "    The input arguments should match the original module so you can pass the inputs to the module.\n",
        "    It should also accept an adapter strategy.\n",
        "\n",
        "    We will then use the method `setup_adapter_strategy()` to prepare the component to be used as an adapter.\n",
        "    Note: Passing None to the strategy will let it pick a default strategy provided by the method\n",
        "    `get_default_strategy_config()`.\n",
        "    \"\"\"\n",
        "    super().__init__(size=size)\n",
        "\n",
        "    # Prepare the adapter strategy\n",
        "    self.setup_adapter_strategy(adapter_strategy)\n",
        "\n",
        "    # Initialize the weights to be 0 at init\n",
        "    self.reset_parameters()\n",
        "\n",
        "  # Note: In this case, because we didn't add new modules, nor change how the original forward works\n",
        "  # We dont need to subclass and override forward() !\n",
        "  \n",
        "  def reset_parameters(self):\n",
        "    # We normally want an adapter at initialization to have no effect on the output\n",
        "    # Therefore we replace the random uniform with a simple identity matrix, which will cause\n",
        "    # the output of the adapter to match the input\n",
        "    with torch.no_grad():\n",
        "      self.model[0].weight = torch.nn.Parameter(torch.eye(self.size))\n",
        "  \n",
        "\n",
        "  def get_default_strategy_config(self) -> 'dataclass':\n",
        "    \"\"\"\n",
        "    Make the default adapter strategy of this component be the `MultiplicationAdapterStrategy()`  \n",
        "    \"\"\"\n",
        "    return MultiplicationAdapterStrategyConfig()"
      ],
      "metadata": {
        "id": "wCcdXIix__Yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----",
        "アダプターが期待通りに動作するかどうかを素早くテストしてみましょう"
      ],
      "metadata": {
        "id": "lYfjhWBtEBYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_adapter = SimpleModuleAdapter(size=5)\n",
        "multiplication_strategy = simple_adapter.adapter_strategy\n",
        "x = torch.randn(1, 5)\n",
        "adapter_x = simple_adapter(x)\n",
        "output = multiplication_strategy(input=x, adapter=simple_adapter, module=None)  # Normally you would pass the module here, but in this example can be skipped.\n",
        "print(\"Original input :\", x)\n",
        "print(\"Adapter output :\", adapter_x)\n",
        "print(\"Strategy output:\", output)"
      ],
      "metadata": {
        "id": "tVkikcmCEJun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "元の入力値がアダプターを通過すると、元の値が問題なく返され、その後アダプター戦略によって2つの値が乗算されます（実質的に入力値の二乗を計算することになります）。",
        "\n",
        "これはカスタムアダプターを作成する十分なデモンストレーションであり、通常は要素ごとの乗算をアダプター戦略として実行することはありません。通常は、戦略の出力が初期化時に少なくとも元の初期化値と等しくなることを好みます。"
      ],
      "metadata": {
        "id": "mi7WpFgxHmGQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adapterコンポーネントに対応するdataclassを設計する",
        "\n",
        "このアダプタコンポーネントの使用をより簡単にするため、コンポーネントを簡単に作成できるデータクラスを用意することをお勧めします。以下に使用例を示します："
      ],
      "metadata": {
        "id": "OrmCQCX6ImKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "\n",
        "@dataclass\n",
        "class SimpleModuleAdapterConfig:\n",
        "    size: int\n",
        "    adapter_strategy: Optional[MultiplicationAdapterStrategyConfig] = None\n",
        "\n",
        "    # mandatory field\n",
        "    _target_: str = \"{0}.{1}\".format(\n",
        "        SimpleModuleAdapter.__module__, SimpleModuleAdapter.__name__\n",
        "    )  "
      ],
      "metadata": {
        "id": "Ml17OoOVJOwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB9qPX1qoqJU"
      },
      "source": [
        "## アダプターモジュールの追加",
        "\n",
        "`MLP` は `AdapterModuleMixin` を継承しているため、新しいアダプターを追加するなど、アダプターモジュールを操作するための一連のメソッドも継承しています。",
        "\n",
        "ユーザーがアダプターを追加したい場合、`add_adapter()` 関数を呼び出し、2つの特定の引数 `name` と `cfg` を指定します。",
        "\n",
        "引数 -",
        "- `name`: モジュールの場合は**ローカルで一意**、モデルの場合は**グローバルで一意**である文字列名を指定します。また、アダプターが特定のモジュールにのみ属することを指定するために「:」記号を使用することも可能です（この使用方法についてはチュートリアルの終盤で詳しく説明します）。",
        "- `cfg`: データクラスまたは OmegaConf 設定オブジェクトで、`_target_` 属性がアダプターモジュールのクラスパスを指し示すほか、必要に応じて追加の属性も含まれます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Du2uPUSdni9D"
      },
      "outputs": [],
      "source": [
        "mlp.add_adapter(name='adapter_1', cfg=adapter_modules.LinearAdapterConfig(in_features=dim, dim=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92vSc2k_xuHk"
      },
      "outputs": [],
      "source": [
        "# Now check the new parameter count of this MLP module, it should be higher than the previous count\n",
        "print(\"New param count :\", mlp.num_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh4qTdTUyWTF"
      },
      "source": [
        "-----",
        "\n",
        "**注意**: 必要な数だけアダプターを追加できます！このチュートリアルでは1つだけ追加しますが、通常は専門化したいタスクごとに1つのアダプターを追加することをお勧めします。",
        "\n",
        "また、複数のアダプターを同時に訓練することは可能ですが（多数のアダプターを追加し、すべて有効化してから凍結解除する方法）、各タスクに対して1つのアダプターのみを訓練することをお勧めします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0CUr4m2sVRH"
      },
      "source": [
        "-----",
        "**注意**: 同じアダプターを複数追加しようとすると、以下のエラーメッセージが表示されます！",
        "\n",
        "注意：アダプター名はモジュールレベルで**ローカルに**一意である必要があり、モデルレベルで**グローバルに**一意である必要があります！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p497PTCBsoIM"
      },
      "outputs": [],
      "source": [
        "# Uncomment to see the error message - \n",
        "# mlp.add_adapter(name='adapter_1', cfg=adapter_modules.LinearAdapterConfig(in_features=dim, dim=10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWgsqsCns4Yr"
      },
      "source": [
        "## 有効化されているすべてのアダプタモジュールを取得",
        "\n",
        "次に、`get_enabled_adapters()` を使用して、現在このモジュールで使用可能なすべての有効化済みアダプターの名前リストを返します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXuGQoFus3qd"
      },
      "outputs": [],
      "source": [
        "mlp.get_enabled_adapters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-UeYsFXtQqj"
      },
      "source": [
        "## アダプターモジュールの状態を設定",
        "\n",
        "上記の方法で有効化されているアダプタ名を取得できますが、アダプタモジュールを有効化または無効化するかどうかを設定するにはどうすればよいでしょうか？",
        "\n",
        "この目的には、`set_enabled_adapter()` メソッドを使用します。いくつかの引数を指定します：",
        "- `name`: アダプターの任意の文字列名を指定できます。このアダプターのみを有効にしたり無効にしたりする際に使用します。`name`を指定しない場合、すべてのアダプターモジュールの状態が新しい値に設定されます。",
        "- `enabled`: ブール値で、このアダプタを有効にするかどうかを指定します。",
        "\n",
        "-----",
        "\n",
        "アダプターを有効にするということは、単にそのアダプターのフォワードパスを有効にするだけで、それ以上の意味はありません。アダプター自体の重みを凍結／解凍するものではなく、他のアダプターと組み合わせてより複雑な相互作用を可能にするものです。",
        "\n",
        "例えば、モデルにアダプターを追加し、学習させた後にモデルを保存することができます。復元したモデルはさらに別のアダプターを追加することが可能です。2つ目のアダプターを学習させる前に、ユーザーは元のモデルの出力ではなく、最初のアダプターの出力を利用することを選択できます。これを実現するため、両方のアダプターを有効にしつつ、最初のアダプターの重みを凍結し、2つ目のアダプターのみを学習させることができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0__7RFaWtPD6"
      },
      "outputs": [],
      "source": [
        "# Disable all adapters\n",
        "mlp.set_enabled_adapters(enabled=False)\n",
        "print(\"Enabled adapters :\", mlp.get_enabled_adapters())\n",
        "\n",
        "# Enable just one adapter\n",
        "mlp.set_enabled_adapters(name=\"adapter_1\", enabled=True)\n",
        "print(\"Enabled adapters :\", mlp.get_enabled_adapters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzT3kwvRubFT"
      },
      "source": [
        "## アダプタモジュールの利用可否 / 有効化状態を確認する",
        "\n",
        "上記の2つの方法を拡張する形で、現在のモジュールにアクティブなアダプタモジュールが存在するかどうかを確認することもできます。そのためには、`is_adapter_available()` 関数を使用できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5quE42kAusiX"
      },
      "outputs": [],
      "source": [
        "mlp.is_adapter_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRCobs9hvEeU"
      },
      "source": [
        "## Adapter Functionality Methods",
        "\n",
        "上記のいくつかの方法は、アダプターをモジュールに追加および変更するための機能の中核を形成しますが、追加されたアダプターモジュール自体は使用しません！",
        "\n",
        "したがって、以下の機能メソッドはアダプターを適切に活用するために使用され、ユーザーが明示的にオーバーライドする必要はありません（ただし、特定の特殊なケースで必要な場合を除く）。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ybsJ9zRx6W7"
      },
      "source": [
        "### `forward_enabled_adapters()`",
        "これらのアダプターを使用するには、`forward_adapter_modules()` メソッドを利用します。",
        "\n",
        "有効化されたアダプタを利用するには、`AdapterModuleMixin`を継承したモジュールはまず有効化されたアダプタが存在するかどうかを確認し、その後このメソッドを呼び出して入力データに対するアダプタモジュールを転送する必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1F9IibFKv9va"
      },
      "outputs": [],
      "source": [
        "# Check `forward_enabled_adapters()`\n",
        "out = mlp.forward_enabled_adapters(input_data)\n",
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzN0RlZI5M-l"
      },
      "source": [
        "### `forward_single_enabled_adapter_()`",
        "アダプターの順方向処理にカスタムロジックを提供するためにサブクラス化可能なメソッドです。例えば、異なる入力セットを持つアダプターを提供したい場合や、順方向処理を実行する前に特定のアダプタータイプをサポートしているかどうかを確認したい場合などに使用します。",
        "\n",
        "アダプターのタイプを確認し、特定のアダプターに入力を転送する前に追加情報を使用することが役立つ場合があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YO2dXe7T5PIQ"
      },
      "outputs": [],
      "source": [
        "# Check `forward_single_enabled_adapter_()`\n",
        "adapter_name = mlp.get_enabled_adapters()[0]  # we have enabled just one adapter\n",
        "adapter_module = mlp.adapter_layer[adapter_name]  # get the adapter module with this name\n",
        "adapter_strategy = adapter_module.adapter_strategy  # get the adapter strategy for this adapter\n",
        "\n",
        "out = mlp.forward_single_enabled_adapter_(input_data, adapter_module, adapter_name=adapter_name, adapter_strategy=adapter_strategy)\n",
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU-OS3wk7FW9"
      },
      "source": [
        "-----",
        "アダプターのフォワードパスとアダプター戦略に関する詳細情報については、アダプターのドキュメントセクションを参照してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1mPF9qVx-HA"
      },
      "source": [
        "### `unfreeze_enabled_adapters()`",
        "アダプターの主な利点の一つは、モデル全体を訓練する必要がないことです。元のモデル/モジュールの残りを凍結したまま、アダプターモジュール自体を訓練することができます。",
        "\n",
        "これは2つのステップで実行できます -",
        "- モデルの最上位レベルで model.freeze() を呼び出す",
        "- `unfreeze_enabled_adapters()` を呼び出して、有効化されているアダプターモジュールのみを再帰的に凍結解除します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6Qdk8YHw5W_"
      },
      "outputs": [],
      "source": [
        "# First setup some utility functions (this is part of NeuralModule)\n",
        "def freeze(m):\n",
        "    for param in m.parameters():\n",
        "      param.requires_grad = False\n",
        "    m.eval()\n",
        "\n",
        "def unfreeze(m):\n",
        "    for param in m.parameters():\n",
        "      param.requires_grad = True\n",
        "    m.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95KGRNwxxlia"
      },
      "outputs": [],
      "source": [
        "freeze(mlp)\n",
        "print(\"MLP frozen params :\", mlp.num_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3xjntCgxhee"
      },
      "outputs": [],
      "source": [
        "# Check `unfreeze_enabled_adapters()` - param count should be lower than the previous total (original + adapter)\n",
        "mlp.unfreeze_enabled_adapters()\n",
        "print(\"MLP unfrozen adapter params :\", mlp.num_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQjz_RIilg1L"
      },
      "source": [
        "# 中級レベルモジュールにおけるアダプターサポート",
        "\n",
        "上記では、`AdapterModuleMixin`を介して単純な`nn.Module`に追加される様々なメソッドと機能について議論しました。ただし、このモジュールはモデルにおける最も基本的な構成要素でした。次に、中間モジュールから下位モジュールへの呼び出しを「ディスパッチ」する方法について見ていきます。",
        "\n",
        "このチュートリアルでは簡潔さを重視し、可能な限り最小限のコード変更に留めます。ただし、下位レベルのモジュールへの中間層ディスパッチをより洗練された形で処理することは十分に可能です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsHudP-bz3bj"
      },
      "source": [
        "## 設定ファイル経由でインスタンス化される中間モジュール",
        "\n",
        "現在、私たちは3段階のモデルを採用しています：",
        "\n",
        "`最上位モデル (SimpleModel) → 中間レベルモジュール (ResidualMLP) → 最下位レベルモジュール (MLP)` という構成になっています。",
        "\n",
        "-----",
        "\n",
        "お気づきかもしれませんが、以前のプリマーチュートリアル（NeMo Model Primer）では、モデルが中間モジュールをインスタンス化するために設定を使用することを推奨しています。これにより、ユーザーは設定を介して同等のモジュールを入れ替えることができ、コードの変更を最小限に抑えつつ、モデル自体の機能を最大限に活用できます。",
        "\n",
        "このような「最終版に近い」モジュールについては、元のモジュールを直接修正するのではなく、元のモジュールを拡張する形で別のAdapter対応モジュールを作成することをお勧めします。これは単に元のモジュールコードを乱雑にしないための好みであり、ユーザーが無視しても構いません。",
        "\n",
        "このガイドでは、ベストプラクティスを実践するための推奨設定を紹介します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f-Y-Oxm1tjH"
      },
      "source": [
        "## Adapter対応の「Penultimate」モジュールを作成する",
        "\n",
        "まず、新しいAdapter互換モジュールを別のクラスとして作成します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DC-L1SsVllLy"
      },
      "outputs": [],
      "source": [
        "# NOTE: We subclass the original ResidualMLP, and add in the AdapterModuleMixin too\n",
        "class ResidualMLPAdapter(ResidualMLP, adapter_mixins.AdapterModuleMixin):\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuIlnrSW2m9t"
      },
      "source": [
        "## アダプターメソッドのオーバーライド",
        "\n",
        "次に、いくつかのアダプタメソッドをオーバーライドし、これらのメソッドを`ResidualMLP`モジュール内のすべての`MLP`ブロックにディスパッチします。",
        "\n",
        "これにより、`MLP`モジュール内で状態を作成/更新し、アダプターモジュールを転送します！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3bcnXIy2mY9"
      },
      "outputs": [],
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "class ResidualMLPAdapter(ResidualMLP, adapter_mixins.AdapterModuleMixin):\n",
        "  def add_adapter(self, name: str, cfg: DictConfig):\n",
        "      # call the same method on each `MLP` layer, collecting results\n",
        "      for layer in self.layers:\n",
        "        layer.add_adapter(name, cfg)\n",
        "      \n",
        "  def get_enabled_adapters(self) -> List[str]:\n",
        "      # call the same method on each `MLP` layer, collecting results\n",
        "      enabled_adapters = set([])\n",
        "      for layer in self.layers:\n",
        "        names = layer.get_enabled_adapters()\n",
        "        enabled_adapters.update(names)\n",
        "      return list(enabled_adapters)\n",
        "  \n",
        "  def set_enabled_adapters(self, name: Optional[str], enabled: bool):\n",
        "      # call the same method on each `MLP` layer, collecting results\n",
        "      for layer in self.layers:\n",
        "        layer.set_enabled_adapters(name, enabled)\n",
        "  \n",
        "  def is_adapter_available(self) -> bool:\n",
        "      # call the same method on each `MLP` layer, collecting results\n",
        "      is_available = any([layer.is_adapter_available() for layer in self.layers])\n",
        "      return is_available"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-RHMG4W4pSY"
      },
      "source": [
        "## 新しいアダプターを登録する",
        "\n",
        "モジュールにアダプター機能を追加するためにサブクラス化する場合、アダプターレジストリにこれらのモジュールを登録することが不可欠です。これにより、後で便利な多くの機能を利用できるようになります。アダプターレジストリは、後でモデル設定をより簡単に更新するために使用できる基本クラスとアダプター互換クラスのグローバルコレクションです。",
        "\n",
        "以下の手順を実行してください：",
        "- `get_registered_adapter()` メソッドを使用して、レジストリがベースクラスを持っているかどうかを確認します。",
        "- 戻り値が None の場合、`register_adapter()` を使用して基底クラスとその互換性のあるアダプタクラスを登録します。",
        "\n",
        "-----",
        "\n",
        "**注意**: この単純なケースでは、最終モジュールの一つ前のモジュールが実際に中間モジュールとなりますが、現実世界のモデルではさらに多くの中間モジュールが存在する場合があります。このような場合、新しいサブクラスを作成せずに直接 `AdapterModuleMixin` を拡張し、前述の手順に従うことでこれらの中間モジュールを更新できます。このようなケースでは、これらモジュールの登録を省略することも可能です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOUo-b042S9m"
      },
      "outputs": [],
      "source": [
        "if adapter_mixins.get_registered_adapter(ResidualMLP) is None:\n",
        "  adapter_mixins.register_adapter(ResidualMLP, ResidualMLPAdapter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSaAnSxC6A6f"
      },
      "source": [
        "-----",
        "\n",
        "これで中間モジュールのサポートを追加する作業は完了です！すべての中間モジュールに同じ（または類似の）コードを追加するのは一見冗長に思えるかもしれませんが、これは最も単純なディスパッチ方式を実装しているためです。",
        "\n",
        "アダプターを構築する方法にはいくつかの興味深いアプローチが存在します。例えば、注意層専用のアダプター（注意層の前後いずれか、または従来の注意ベースブロックにおける最終フィードフォワード層専用のアダプター）などが挙げられます。このようなアプローチにより、中間層はこれらの機能を下位層に委譲する完全な柔軟性を有しています。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yeL62Js6sGb"
      },
      "source": [
        "# 最上位モデルにおけるアダプターサポート",
        "\n",
        "最後に、中間モジュールから最下層モジュールへの上記メソッドのディスパッチが完了した後、モデル自体から最初のモジュール（または後方移動時は最後から2番目のモジュール）への最終ディスパッチを実行する必要があります。",
        "\n",
        "このケースでは、これまで使用してきたも `AdapterModuleMixin` とは異なるミックスインクラスを継承します。代わりに、モデルレベルの設定管理機能が組み込まれた `AdapterModelPTMixin` を継承します - これには、アダプター互換モデルの保存と復元を含むモデルレベルの設定管理機能が組み込まれています！",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQpl_ML78Pw2"
      },
      "source": [
        "## `AdapterModelPTMixin`の拡張",
        "\n",
        "トップレベルのミックスインを継承する方法は2通りあります：",
        "\n",
        "(1)  現在の Model クラス内で直接拡張する",
        "\n",
        "(2) 追加機能を実装したクラスを作成し、その後そのクラスを継承する。",
        "\n",
        "選択肢 (2) は一見すると目的 (1) を達成するための遠回りな方法のように思えるかもしれません。しかし、これはアダプター管理のロジックを複雑な Model コードベースの外部に保持するためです。Model 自体は、モジュールの設定、データローダー、最適化器/スケジューラ、損失関数、評価指標、そして PyTorch Lightning の「ステップ」（訓練、検証、テストの各ステップ）といった多くの重要な詳細事項に関与しているためです。",
        "\n",
        "-----",
        "このチュートリアルでは明確性の観点からオプション (2) を採用します。また、各ステップごとに新しいサブクラスを作成することには透明性を確保する目的があります（同時に大量の情報を提示して読者に負担をかけないためでもあります）。これらの手順はすべて、単一の新しいクラス内で実行することが推奨されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85eprLBu55a0"
      },
      "outputs": [],
      "source": [
        "class SimpleModelAdapter(adapter_mixins.AdapterModelPTMixin):\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j38nVuRoCiMb"
      },
      "outputs": [],
      "source": [
        "help(adapter_mixins.AdapterModelPTMixin)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ILtH3PT8PQs"
      },
      "source": [
        "## 選択的なディスパッチのためのメソッドのオーバーライド",
        "\n",
        "アダプター呼び出しを次のモジュールに振り分ける方法には明らかな違いがありました。これは、モジュールが同質的で典型的な動作を共有していたためです。",
        "\n",
        "しかし、後続のレイヤーがモデルレベルで標準的な動作を共有する理由はありません。`encoder` と `decoder` Transformer レイヤーの観点で考えてみてください - これらは根本的に異なるモジュールです！したがって、それらのアダプターが類似している必要がある理由は何でしょうか？",
        "\n",
        "最上位レベルでは、ユーザー入力を活用して、このような論理的に異種のコンポーネント向けのアダプターをどのように構築するかを決定できます。以下のセクションでは、**グローバル**および**モジュール**レベルのアダプターを活用して、Modelの各**コンポーネント**向けのアダプターの動作と構築を分離する方法について説明します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EwR-Onc-xbr"
      },
      "source": [
        "## setup_adapters() のオーバーライド",
        "\n",
        "モデルを復元する際には、内部に含まれるすべてのモジュールのパラメータを慎重にロードする必要があります。これまで、torch.nn.Module に Adapter の情報と機能を追加することはできましたが、これらの情報はどこにも保存していませんでした。",
        "\n",
        "したがって、ノートブックを閉じて保存済みチェックポイントを復元しようとすると、復元は失敗します。新しいモデルには以前に追加したアダプターの情報が含まれていないため、state dictのマッチングが失敗します。",
        "\n",
        "この問題は、`setup_adapters()` をオーバーライドし、Model コンストラクタ内でそれを呼び出すことで解決できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsSAb99a9l86"
      },
      "outputs": [],
      "source": [
        "# Import the class explicitly to make instance checks easier\n",
        "from nemo.core.classes.mixins.adapter_mixins import AdapterModuleMixin\n",
        "\n",
        "class SimpleModelAdapterSetupAdapters(SimpleModelAdapter):\n",
        "  def setup_adapters(self):\n",
        "    # First check that any of the modules support adapters or not\n",
        "    supports_adapters = False\n",
        "\n",
        "    # Check the inheriting class' modules supports adapters or not\n",
        "    if hasattr(self, 'encoder') and isinstance(self.encoder, AdapterModuleMixin):\n",
        "        supports_adapters |= True\n",
        "\n",
        "    if hasattr(self, 'decoder') and isinstance(self.decoder, AdapterModuleMixin):\n",
        "        supports_adapters |= True\n",
        "\n",
        "    # If any class supports it, try to restore adapters\n",
        "    if supports_adapters:\n",
        "        super().setup_adapters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvmY6XJtApK4"
      },
      "source": [
        "-----",
        "\n",
        "このステップでは、作成したモジュールのいずれかがアダプタをサポートしているかどうかを確認します。もしサポートしているモジュールがあれば、super()メソッドを呼び出して、必要に応じてアダプタを復元しようとします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2eTu1pFA2j-"
      },
      "source": [
        "## add_adapter() のオーバーライド",
        "\n",
        "次に、`add_adapter`をオーバーライドします。コードに進む前に、まずNeMoでサポートされているアダプターの種類について議論する必要があります。",
        "\n",
        "- `Global Adapters`: これらのアダプターは名称と機能の両面で全てのサポート対象モジュールと共通しています。複数のモデルコンポーネント間で単一のアダプターを共有できる場合に特に有用です。例えば、エンコーダーとデコーダーは同じアダプターを共有しています。",
        "- `Module Adapters`: これらのアダプタは特定のモジュール専用であり、そのためモデルの複数コンポーネント間で名前を共有することはできません。アダプタ名は `{module_name}:{adapter_name}` という形式で指定されます。",
        "\n",
        "**注意**: モジュールアダプタを追加した後、そのアダプタは名前の `adapter_name` 部分だけで参照できます。`module_name` を再度指定する必要はありません。なぜなら、すべてのアダプタ名は Model レベルでグローバルに一意であることが保証されているからです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W47wBr-eB6IR"
      },
      "source": [
        "-----",
        "\n",
        "ユーザーがサポートすべきアダプターは、`Global Adapters`、`Module Adapters`、あるいはその両方です。本チュートリアルでは、両方をサポートするとともに、`encoder`用の`Default Module Adapter`も追加サポートします。",
        "\n",
        "**注意**: `Global` アダプターと `Module` アダプターを区別しやすくするため、便利なメソッド `resolve_adapter_module_name_(name)` の使用を推奨します。使用可能なアダプターモジュールを判定するには、プロパティ `adapter_module_names` の使用をお勧めします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCFZt7GCCQ1K"
      },
      "outputs": [],
      "source": [
        "class SimpleModelAdapterAddAdapter(SimpleModelAdapterSetupAdapters):\n",
        "\n",
        "  def add_adapter(self, name: str, cfg: DictConfig):\n",
        "      # Setup the config first. At the model level, super does not automatically call any of the subclass methods\n",
        "      # It just sets up the model.cfg for users\n",
        "      super().add_adapter(name, cfg)\n",
        "\n",
        "      # Resolve module name and adapter name\n",
        "      module_name, adapter_name = self.resolve_adapter_module_name_(name)\n",
        "\n",
        "      # Try to retrieve global adapter config\n",
        "      global_config = self._get_global_cfg()\n",
        "\n",
        "      # forward the method call to the individual modules\n",
        "      # If module name is empty, it is a default and global adapter, otherwise it is a module adapter\n",
        "      if (module_name == '' and global_config.get('encoder_adapter', True)) or (module_name == 'encoder'):\n",
        "          self.encoder.add_adapter(name, cfg)\n",
        "\n",
        "      if (module_name == '' and global_config.get('decoder_adapter', False)) or (module_name == 'decoder'):\n",
        "          self.decoder.add_adapter(name, cfg)\n",
        "    \n",
        "  def resolve_adapter_module_name_(self, name: str) -> (str, str):\n",
        "      # resolve name and module\n",
        "      module_name, adapter_name = super().resolve_adapter_module_name_(name)\n",
        "\n",
        "      # '' as module name means \"default module\"\n",
        "      # assert that the module name (if provided) is valid - default, encoder or decoder\n",
        "      valid_module_names = self.adapter_module_names  # Get the list of supported adapter modules from property\n",
        "      if module_name not in valid_module_names:\n",
        "          raise ValueError(f\"Provided module name `{module_name}` is not in valid list : {valid_module_names}\")\n",
        "\n",
        "      return (module_name, adapter_name)\n",
        "\n",
        "  def _get_global_cfg(self):\n",
        "      # Utility method to get a default \"global\" adapter config (can be given any value by the user in this config)\n",
        "      global_config = DictConfig({})\n",
        "      if 'adapters' in self.cfg and self.adapter_global_cfg_key in self.cfg.adapters:\n",
        "          global_config = self.adapter_cfg[self.adapter_global_cfg_key]\n",
        "      return global_config\n",
        "\n",
        "  @property\n",
        "  def adapter_module_names(self) -> List[str]:\n",
        "      module_names = super().adapter_module_names  # \"Default\" adapter module: ''\n",
        "      module_names.extend(['encoder', 'decoder'])  # Add support for `encoder` and `decoder` modules\n",
        "      return module_names\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHAZFqo7DrCV"
      },
      "source": [
        "-----",
        "\n",
        "このコード量が多いため、分解して説明します。まず定義されているユーティリティメソッド `_get_global_cfg()` は、モデル設定から「model.cfg.adapters.global_cfg」というサブ設定を取得しようとします。この設定はユーザーが定義するもので、必要に応じて任意のロジックを設定するために使用できます。見つからない場合は、代わりにデフォルトの辞書が作成されます。",
        "\n",
        "次に、`resolve_adapter_module_name_(name)` メソッドをオーバーライドします。このベースクラスのメソッドは文字列名を受け取り、それを `module_name` と `adapter_name` に分割しようとします。このメソッドをオーバーライドして、有効な `module_name` が存在することを断言します。",
        "\n",
        "-----",
        "\n",
        "最後に、`add_adapter` メソッドをオーバーライドします。まず super() を呼び出して設定を更新します。次に、オーバーライドした `resolve_adapter_module_name_(name)` メソッドを呼び出して提供されたアダプタ名が有効かどうかを確認します。その後、モデル設定に存在する場合はアダプタの `global_cfg` を取得します。",
        "\n",
        "この情報をもとに、必要に応じてアダプターを追加できるようになりました。「ユーザー定義」ロジックを実装しており、以下のいずれかの条件が満たされた場合にエンコーダーアダプターを追加します。",
        "- ユーザーがデフォルトのモジュール名を持つ「Global」アダプターを指定するか、あるいは`global_cfg.encoder_adapter`の値をTrueに設定している場合（デフォルトではTrue）、これは少なくともエンコーダーアダプターがデフォルトで必ず追加されることを意味します。",
        "- ユーザーが `decoder` モジュール名を持つ `Module` アダプターを提供するか、明示的に `global_cfg.decoder_adapter` フラグを True に設定している場合（デフォルトは False）。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fVSt9wPFK7U"
      },
      "source": [
        "## get_enabled_adapters() のオーバーライド",
        "\n",
        "次に、`get_enabled_adapters()`メソッドをオーバーライドします。これは通常、Modelコンポーネントがアダプターをサポートしているかどうかを確認し、サポートしている場合にはそれらのノードの結果を収集して統合するだけで済む簡単な処理です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuwE_mLXAko6"
      },
      "outputs": [],
      "source": [
        "class SimpleModelAdapterGetEnabledAdapters(SimpleModelAdapterAddAdapter):\n",
        "\n",
        "  def get_enabled_adapters(self) -> List[str]:\n",
        "      enabled_adapters = super().get_enabled_adapters()\n",
        "\n",
        "      # Forward the method call to the individual modules\n",
        "      if isinstance(self.encoder, AdapterModuleMixin):\n",
        "          encoder_adapters = self.encoder.get_enabled_adapters()\n",
        "          enabled_adapters.extend(encoder_adapters)\n",
        "\n",
        "      if isinstance(self.decoder, AdapterModuleMixin):\n",
        "          decoder_adapters = self.decoder.get_enabled_adapters()\n",
        "          enabled_adapters.extend(decoder_adapters)\n",
        "\n",
        "      return enabled_adapters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0fgtkVqFvFS"
      },
      "source": [
        "## set_enabled_adapters() のオーバーライド",
        "\n",
        "上記と同様に、コンポーネントがアダプターをサポートしているかどうかを確認する必要があり、サポートされている場合はそれらのコンポーネントにコールをディスパッチします。",
        "\n",
        "**注意**: ここでは通常の継承チェックではなく、論理チェックを行います。継承チェックだけでは、コンポーネントがアダプターを追加したかどうかまでは判断できません。私たちは「デフォルト/グローバル/モジュールエンコーダー」と「モジュールデコーダー」アダプターの2つの使用ケースがあるため、これらの条件を確認する必要があります。",
        "\n",
        "**注2**: ご存知の通り、set_enabled_adapters() 関数はアダプターの状態をすべて設定する際に `None` を名前として受け取ります。ただし、`resolve_adapter_module_name(name)` メソッドは常に有効な文字列名を受け取る必要があります。そのため、このメソッドに `None` を渡さないように注意してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuuzuedEFt4Y"
      },
      "outputs": [],
      "source": [
        "class SimpleModelAdapterSetEnabledAdapters(SimpleModelAdapterGetEnabledAdapters):\n",
        "\n",
        "  def set_enabled_adapters(self, name: Optional[str] = None, enabled: bool = True):\n",
        "      # check if valid model with some adapter support\n",
        "      super().set_enabled_adapters(name, enabled)\n",
        "\n",
        "      # Resolve module name and adapter name\n",
        "      if name is not None:\n",
        "          module_name, _ = self.resolve_adapter_module_name_(name)\n",
        "      else:\n",
        "          module_name = None\n",
        "\n",
        "      # Try to retrieve global adapter config\n",
        "      global_config = self._get_global_cfg()\n",
        "\n",
        "      # Forward the method call to the individual modules\n",
        "      # Note the OR checks - \n",
        "      # if module_name is None - ie explicitly None was passed, set the state for all modules\n",
        "      # if module name was '' or 'encoder, or if `global_cfg.encoder_adapter` was true, or module_name was '' or 'encoder', forward to encoder.\n",
        "      # if `global_cfg.decoder_adapter` was true, or module_name was 'decoder', forward to decoder.\n",
        "      # The user can chose to simplify this logic, or add more complex logic as required.\n",
        "      if name is None or global_config.get('encoder_adapter', True) or module_name in ('', 'encoder'):\n",
        "        if self.encoder.is_adapter_available():\n",
        "          self.encoder.set_enabled_adapters(name, enabled)\n",
        "\n",
        "      if name is None or global_config.get('decoder_adapter', False) or module_name == 'decoder':\n",
        "        if self.decoder.is_adapter_available():\n",
        "          self.decoder.set_enabled_adapters(name, enabled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPf5ga4YH0lb"
      },
      "source": [
        "## `check_valid_model_with_adapter_support_()` のオーバーライド",
        "\n",
        "上記の実装では、モデルのコンポーネントがアダプターをサポートしているかどうかの暗黙的なチェックを行い、その結果を処理しています。これは許容範囲内ですが、無効なアクションの組み合わせについてより厳密なチェックを行い、意味のある警告やエラーを発生させたい場合があります。",
        "\n",
        "この目的のために、`check_valid_model_with_adapter_support()_`メソッドを提供しています。このメソッドはほぼすべてのアダプター操作の前に呼び出され、いくつかの真理を主張しようとします。ユーザーはここで任意のエラーや警告を発生させることで、無効な操作/設定についてユーザーに通知することができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4vM2u3FHvaN"
      },
      "outputs": [],
      "source": [
        "from nemo.utils import logging, logging_mode\n",
        "\n",
        "class SimpleModelAdapterFinal(SimpleModelAdapterSetEnabledAdapters):\n",
        "\n",
        "  def check_valid_model_with_adapter_support_(self):\n",
        "      global_cfg = DictConfig({})\n",
        "      if self.adapter_global_cfg_key in self.adapter_cfg:\n",
        "          global_cfg = self.adapter_cfg[self.adapter_global_cfg_key]\n",
        "\n",
        "      encoder_adapter = global_cfg.get('encoder_adapter', True)\n",
        "      decoder_adapter = global_cfg.get('decoder_adapter', False)\n",
        "\n",
        "      if encoder_adapter and not hasattr(self, 'encoder'):\n",
        "          logging.warning(\"Encoder not available\", mode=logging_mode.ONCE)\n",
        "      elif encoder_adapter and not isinstance(self.encoder, AdapterModuleMixin):\n",
        "          logging.warning(\"Encoder does not support adapters !\", mode=logging_mode.ONCE)\n",
        "\n",
        "      if decoder_adapter and not hasattr(self, 'decoder'):\n",
        "          logging.warning(\"Decoder is not available\", mode=logging_mode.ONCE)\n",
        "      elif decoder_adapter and not isinstance(self.decoder, AdapterModuleMixin):\n",
        "          logging.warning(\"Decoder does not support adapters !\", mode=logging_mode.ONCE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTVGaXpqIzWH"
      },
      "source": [
        "## モデルの更新",
        "\n",
        "最上位の Model ミックスインクラスを個別に実装した後、元の Model に簡単に組み込むことができます。チュートリアルの都合上、ここでコードを複製しますが、Model をサブクラス化して `__init__` メソッドをオーバーライドすることで同様の機能を実現することも可能です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tl4aJr9zIx_v"
      },
      "outputs": [],
      "source": [
        "# Note how we added `SimpleModelAdapterFinal` to the class inheritance scheme.\n",
        "# The only other change is the addition of `self.setup_adapters()` to the __init__ method.\n",
        "class SimpleModel(ModelPT, SimpleModelAdapterFinal):\n",
        "    def __init__(self, cfg, trainer=None):\n",
        "        super().__init__(cfg, trainer=trainer)\n",
        "\n",
        "        self.encoder = instantiate(cfg.encoder)  # type: ResidualMLP\n",
        "        self.decoder = instantiate(cfg.decoder)  # type: ResidualMLP\n",
        "        self.projection = nn.Linear(self.decoder.dim, cfg.out_features)\n",
        "\n",
        "        # NOTE: The only important change - calling `setup_adapters()` !\n",
        "        self.setup_adapters()\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.encoder(x)\n",
        "        z = self.decoder(y)\n",
        "        out = self.projection(z)\n",
        "        return out\n",
        "\n",
        "    def list_available_models(cls):\n",
        "        return []\n",
        "\n",
        "    def setup_training_data(self, train_data_config):\n",
        "        pass\n",
        "\n",
        "    def setup_validation_data(self, val_data_config):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HqU-8pBJjlP"
      },
      "source": [
        "-----",
        "\n",
        "これで完了です！新しいミックスインをサブクラス化し、`setup_adapters()`を呼び出すだけで、必要な変更は完了です！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFlt2sCPJgvU"
      },
      "outputs": [],
      "source": [
        "old_config = get_model_config(dim)\n",
        "model = SimpleModel(old_config)\n",
        "model.summarize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LioRW_TJ6Qs"
      },
      "source": [
        "-----",
        "\n",
        "では、このモデルに `decoder` Moduleアダプターを追加してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9W5B_0wiJ0V5"
      },
      "outputs": [],
      "source": [
        "# This cell will error out if uncommented\n",
        "# model.add_adapter(\"decoder:adapter_1\", cfg=adapter_modules.LinearAdapterConfig(in_features=dim, dim=5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW71Jhq_KhD7"
      },
      "source": [
        "-----",
        "\n",
        "エラーメッセージ `Encoder does not support adapters !` が表示されます。これは、モデルの元の設定 (`old_config`) には `ResidualMLP` クラスへのクラスパスが含まれていますが、`ResidualMLPAdapter` クラスへのパスは含まれていないためです！",
        "\n",
        "これは簡単に修正可能です。なぜなら、このクラスはすでに適切に登録済みだからです（「新しいアダプターを登録する」サブセクションを参照）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyvHTCjpKgKi"
      },
      "outputs": [],
      "source": [
        "def get_adapter_model_config() -> DictConfig:\n",
        "  config = get_model_config()\n",
        "\n",
        "  # Find the metadata in the registry, and get the correct adapter capable class path\n",
        "  enc_adapter_metadata = adapter_mixins.get_registered_adapter(config.encoder._target_)\n",
        "  if enc_adapter_metadata is not None:\n",
        "      print(\"Updated encoder to support adapters !\")\n",
        "      config.encoder._target_ = enc_adapter_metadata.adapter_class_path\n",
        "\n",
        "  # Find the metadata in the registry, and get the correct adapter capable class path\n",
        "  dec_adapter_metadata = adapter_mixins.get_registered_adapter(config.decoder._target_)\n",
        "  if dec_adapter_metadata is not None:\n",
        "      print(\"Updated decoder to support adapters !\")\n",
        "      config.decoder._target_ = dec_adapter_metadata.adapter_class_path\n",
        "\n",
        "  return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5HD91NwKMTp"
      },
      "outputs": [],
      "source": [
        "new_config = get_adapter_model_config()\n",
        "model = SimpleModel(new_config)\n",
        "model.summarize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvnZW4Y8LnEH"
      },
      "source": [
        "-----",
        "では、`decoder` Module Adapterを再度追加してみましょう："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCYE7afTLcYY"
      },
      "outputs": [],
      "source": [
        "model.add_adapter('decoder:adapter_1', cfg=adapter_modules.LinearAdapterConfig(in_features=dim, dim=5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4enwIFsL3BE"
      },
      "source": [
        "-----",
        "複数のログメッセージが表示され、`adapter_1`が追加されたことが示されます（各ブロックごとに1つずつ）。次に、アダプタが正しいモジュールに存在するかどうかを確認します -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXBD5l1PL0zm"
      },
      "outputs": [],
      "source": [
        "print(\"Encoder adapter available :\", model.encoder.is_adapter_available())\n",
        "print(\"Decoder adapter available :\", model.decoder.is_adapter_available())\n",
        "print(\"Decoder adapter(s) :\", model.decoder.get_enabled_adapters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKRWH0ZSMBpR"
      },
      "outputs": [],
      "source": [
        "model.summarize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw8ZXBBYMnVH"
      },
      "source": [
        "## Adapterのトレーニング準備",
        "\n",
        "最終的に、モデルにアダプター機能が追加されたことで、モデルの他の部分を凍結したままアダプターのみを訓練できるようになりました。",
        "\n",
        "次のセクションでは、このセットアップを実行する方法を説明します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyNB7Jh0Mp2q"
      },
      "outputs": [],
      "source": [
        "# disable all adapters, enable just one adapter that we want to train\n",
        "model.set_enabled_adapters(enabled=False)\n",
        "model.set_enabled_adapters('adapter_1', enabled=True)  # note : we directly use the adapter_name of adapter_1\n",
        "\n",
        "# freeze all the weights, unfreeze just the enabled adapters\n",
        "model.freeze()\n",
        "model.unfreeze_enabled_adapters()\n",
        "\n",
        "print()\n",
        "model.summarize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1aA0GxI_kKc"
      },
      "source": [
        "## アダプターの保存と復元",
        "\n",
        "このモデルを実装した今、`model.save_to()` を使用してアダプターサポートを含む完全な NeMo モデルを保存できます。このアダプターモデルを保存してから復元してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AH_v_InH_xhO"
      },
      "outputs": [],
      "source": [
        "model.save_to('full_model.nemo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LH0FNfVHAs4u"
      },
      "outputs": [],
      "source": [
        "!ls -d -- *.nemo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Z_kajXeBDyI"
      },
      "outputs": [],
      "source": [
        "new_model = ModelPT.restore_from('full_model.nemo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvTufIQWBNgi"
      },
      "outputs": [],
      "source": [
        "new_model.decoder.get_enabled_adapters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OzpPgfxBda1"
      },
      "source": [
        "-----",
        "\n",
        "モデル全体を保存・復元することは可能ですが、必ずしも必要ではありません。ここでアダプターについて考えてみましょう - これらは基本モデルの上に追加されるモジュールです。新しいアダプターを追加するたびに、モデル全体をファイルに保存・復元するのは現実的ではありません（特にモデルのパラメータ数が数十億にもなる場合はなおさらです！）。",
        "\n",
        "次に、`save_adapters()` を使用してモジュール自体のみを個別の .pt ファイルに保存・復元する方法について説明します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jbf23dgFB8NU"
      },
      "outputs": [],
      "source": [
        "model.save_adapters('adapters.pt', name=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-dkPsxNCEGv"
      },
      "outputs": [],
      "source": [
        "!du -sh adapters.pt full_model.nemo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJc-dA7aCH5I"
      },
      "source": [
        "-----",
        "ご覧の通り、モデル全体はアダプターモジュール自体よりもはるかに大きなサイズになります。これにより、モデル全体のディスク容量を消費することなく、アダプターモジュールのみを他者と共有することが可能になります。",
        "\n",
        "次に、`load_adapters()` を使用してこのようなアダプターチェックポイントを新しいモデルに復元する方法を示します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3w2ob6_ECgxf"
      },
      "outputs": [],
      "source": [
        "new_config = get_adapter_model_config()\n",
        "model_2 = SimpleModel(new_config)\n",
        "model_2.summarize()  # no adapters in basic model with adapter support"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmceRIylCnry"
      },
      "outputs": [],
      "source": [
        "model_2.load_adapters('adapters.pt', name=None, map_location='cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qEjDjcLEfC2"
      },
      "outputs": [],
      "source": [
        "model_2.freeze()\n",
        "model_2.unfreeze_enabled_adapters()\n",
        "model_2.summarize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a80Pt-_5E_kN"
      },
      "outputs": [],
      "source": [
        "model_2.get_enabled_adapters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzk6hXGuEdqm"
      },
      "source": [
        "-----",
        "上記のモデルに`None`を渡してすべてのアダプターを復元しましたが、チェックポイントから単一のアダプターだけを復元したい場合はどうすればよいでしょうか？その場合は、`load_adapters()`メソッドに`name`引数を渡すことで実現できます。",
        "\n",
        "注意: ここで指定する名前は、アダプター自体を作成する際に使用した名前である必要があります。したがって、モジュールレベルのアダプターの場合は、`module_name` も指定する必要があります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg48swJpMiS5"
      },
      "source": [
        "# 関連文献",
        "\n",
        "アダプターに関する詳細情報については、NeMoドキュメントページのアダプターセクションを参照してください。また、アダプターモジュールを作成する方法について詳しく説明したセクションも含まれています。",
        "\n",
        "アダプターの具体的な使用方法については、以下の関連記事をご参照ください -",
        "- [Parameter-Efficient Transfer Learning for NLP](https://arxiv.org/abs/1902.00751)",
        "- [Exploiting Adapters for Cross-lingual Low-resource Speech Recognition](https://arxiv.org/abs/2105.11905)",
        "- [Efficient Adapter Transfer of Self-Supervised Speech Models for Automatic Speech Recognition](https://arxiv.org/abs/2202.03218)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iz2wF3cd-6MF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "8eH6mW792lkY"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}